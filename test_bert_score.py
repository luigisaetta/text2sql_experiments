"""
To compare SQL generated with Golden query (generated by another LLM)
"""

import re
import warnings
import logging

import bert_score

from tqdm import tqdm


from core_functions import (
    create_db_engine,
    get_formatted_schema,
    generate_sql_query_with_models,
    get_chat_models,
)
from utils import get_console_logger


# suppress warnings for bert score
warnings.filterwarnings(
    "ignore", category=FutureWarning, module="transformers.tokenization_utils_base"
)
logging.getLogger("transformers.modeling_utils").setLevel(logging.ERROR)


# SH schema
# file with NL requests
TESTS_FILE_NAME = "testsh50.txt"
# TESTS_FILE_NAME = "testhr30.txt"
# file with expected (golden) SQL
GOLDEN_TRUTH_FILE = "golden_truth_sh50.txt"
# GOLDEN_TRUTH_FILE = "golden_truth_hr30.txt"

# read list of NL requests
with open(TESTS_FILE_NAME, "r", encoding="UTF-8") as file:
    USER_QUERIES = [linea.strip() for linea in file]

# read golden truth
sql_queries = []
with open(GOLDEN_TRUTH_FILE, "r", encoding="UTF-8") as g_file:
    for linea in g_file:
        if linea.startswith("#"):
            # comment, ignore
            pass
        else:
            # remove " at beginning and end
            linea = linea.replace('"', "")
            sql_queries.append(linea)

logger = get_console_logger()

model_list = get_chat_models()

engine = create_db_engine()

# create the schema with Llama3
SCHEMA = get_formatted_schema(engine, model_list[0])

# to limit how many we test
TO_TEST = 30

# put the generated sql in another list
generated_sql_list = []

sql_queries = sql_queries[:TO_TEST]
USER_QUERIES = USER_QUERIES[:TO_TEST]


print("")
print("Generating SQL...")
print("")

total_length = min(len(USER_QUERIES), len(sql_queries))

for user_query, sql_query in tqdm(zip(USER_QUERIES, sql_queries), total=total_length):

    # what happens if generated query is wrong?
    # it is checked internally in generate... call
    # and if syntax is wrong it returns an empty string
    sql_query_generated = generate_sql_query_with_models(
        user_query, SCHEMA, engine, model_list
    )

    # normalize the generated sql
    # remove newline -> single line
    sql_query_generated = sql_query_generated.replace("\n", " ")
    # replace multiple blanks adiacent with a single blank
    sql_query_generated = re.sub(r"\s+", " ", sql_query_generated)

    generated_sql_list.append(sql_query_generated)

generated_sql_list = generated_sql_list[:TO_TEST]

# Calculate BERTScore
print("")
print("Computing BERT score...")
print("")
P, R, F1 = bert_score.score(generated_sql_list, sql_queries, lang="en", verbose=True)

print("")
print("Scores:")
print("")

for i, (p, r, f) in enumerate(zip(P, R, F1)):
    print(f"SQL Pair {i+1}: Precision: {p:.4f}, Recall: {r:.4f}, F1 Score: {f:.4f}")

print("")
print("")
