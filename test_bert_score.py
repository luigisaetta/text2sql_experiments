"""
To compare SQL generated with Golden query (generated by another LLM)
"""

import re
import warnings
import logging

import bert_score

from tqdm import tqdm

from database_manager import DatabaseManager
from llm_manager import LLMManager

from core_functions import (
    get_formatted_schema,
    generate_sql_with_models,
)
from prompt_template import PROMPT_TEMPLATE
from utils import get_console_logger
from config import CONNECT_ARGS, MODEL_LIST, ENDPOINT, TEMPERATURE
from config_private import COMPARTMENT_OCID


def normalize_sql(input_sql):
    """
    apply some normalizations to SQL to make comparison and compute of bert score easier
    """
    # normalize the generated sql
    # remove newline -> single line
    query_generated = input_sql.replace("\n", " ")
    # replace multiple blanks adiacent with a single blank
    query_generated = re.sub(r"\s+", " ", query_generated)

    return query_generated


#
# Main
#
# suppress warnings for bert score
warnings.filterwarnings(
    "ignore", category=FutureWarning, module="transformers.tokenization_utils_base"
)
logging.getLogger("transformers.modeling_utils").setLevel(logging.ERROR)


# SH schema
# file with NL requests
TESTS_FILE_NAME = "testsh50.txt"
GOLDEN_TRUTH_FILE = "golden_truth_sh50.txt"

# TESTS_FILE_NAME = "testhr30.txt"
# GOLDEN_TRUTH_FILE = "golden_truth_hr30.txt"
# file with expected (golden) SQL


# read list of NL requests
with open(TESTS_FILE_NAME, "r", encoding="UTF-8") as file:
    USER_QUERIES = [linea.strip() for linea in file]

# read golden truth
sql_queries = []
with open(GOLDEN_TRUTH_FILE, "r", encoding="UTF-8") as g_file:
    for linea in g_file:
        if linea.startswith("#"):
            # comment, ignore
            pass
        else:
            # remove " at beginning and end
            linea = linea.replace('"', "")
            sql_queries.append(linea)

logger = get_console_logger()

db_manager = DatabaseManager(CONNECT_ARGS, logger)
llm_manager = LLMManager(MODEL_LIST, ENDPOINT, COMPARTMENT_OCID, TEMPERATURE, logger)

engine = db_manager.engine
# 0 is llama3-70B
llm1 = llm_manager.llm_models[0]

# create the schema with Llama3
SCHEMA = get_formatted_schema(engine, llm1)

# to limit how many we test
TO_TEST = 50

# put the generated sql in another list
generated_sql_list = []

sql_queries = sql_queries[:TO_TEST]
USER_QUERIES = USER_QUERIES[:TO_TEST]


print("")
print("Generating SQL...")
print("")

total_length = min(len(USER_QUERIES), len(sql_queries))

for user_query, sql_query in tqdm(zip(USER_QUERIES, sql_queries), total=total_length):

    sql_query = generate_sql_with_models(
        user_query, SCHEMA, db_manager, llm_manager, PROMPT_TEMPLATE
    )

    # normalize the generated sql
    # remove newline -> single line
    sql_query_normalized = normalize_sql(sql_query)

    generated_sql_list.append(sql_query_normalized)

generated_sql_list = generated_sql_list[:TO_TEST]

# Calculate BERTScore
print("")
print("Computing BERT score...")
print("")
P, R, F1 = bert_score.score(generated_sql_list, sql_queries, lang="en", verbose=True)

print("")
print("Scores:")
print("")

for i, (p, r, f) in enumerate(zip(P, R, F1)):
    print(f"SQL Pair {i+1}: Precision: {p:.4f}, Recall: {r:.4f}, F1 Score: {f:.4f}")

print("")
print("")
