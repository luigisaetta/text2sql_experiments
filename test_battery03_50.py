"""
Battery of test03

These are tests generated by GPT-=
"""

from tqdm import tqdm
from sqlalchemy import text
from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI

from core_functions import (
    create_db_engine,
    get_formatted_schema,
    generate_sql_query,
    generate_sql_query_with_pair_models,
)
from utils import get_console_logger
from config_private import ENDPOINT, COMPARTMENT_OCID, MODEL_LIST

# SH schema
# Nome del file da leggere
nome_file = "testsh50.txt"

USER_QUERIES = []

# Leggi il file riga per riga e carica ogni riga in una lista
with open(nome_file, "r") as file:
    USER_QUERIES = [linea.strip() for linea in file]

# 0 is command-r-plus
MODEL_NAME1 = MODEL_LIST[0]
MODEL_NAME2 = MODEL_LIST[1]

logger = get_console_logger()

llm1 = ChatOCIGenAI(
    model_id=MODEL_NAME1,
    service_endpoint=ENDPOINT,
    compartment_id=COMPARTMENT_OCID,
    model_kwargs={"temperature": 0, "max_tokens": 2048},
)
llm2 = ChatOCIGenAI(
    model_id=MODEL_NAME1,
    service_endpoint=ENDPOINT,
    compartment_id=COMPARTMENT_OCID,
    model_kwargs={"temperature": 0, "max_tokens": 2048},
)

engine = create_db_engine()

SCHEMA = get_formatted_schema(engine, llm1)

N_QUERIES = 0
N_OK = 0

print("")
print("LLMs used: ", MODEL_NAME1 + "-" + MODEL_NAME2)
print("")

for user_query in tqdm(USER_QUERIES):
    N_QUERIES += 1

    sql_query = generate_sql_query_with_pair_models(
        user_query, SCHEMA, engine, llm1, llm2, verbose=True
    )

    # generate with pairs check the sintax
    # if sintx is wromg return empty string
    if len(sql_query) > 0:
        N_OK += 1

print("")
print("Summary of Test results:")
print("Number of queries: ", N_QUERIES)
print("Number of test ok: ", N_OK)
