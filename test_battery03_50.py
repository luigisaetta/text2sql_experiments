"""
Battery of test03

These are tests generated by GPT-=
"""

from tqdm import tqdm
from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI

from core_functions import (
    create_db_engine,
    get_formatted_schema,
    generate_sql_query_with_models,
)
from utils import get_console_logger
from config_private import ENDPOINT, COMPARTMENT_OCID, MODEL_LIST

# SH schema
# Nome del file da leggere
TESTS_FILE_NAME = "testsh50.txt"

# Leggi il file riga per riga e carica ogni riga in una lista
with open(TESTS_FILE_NAME, "r", encoding="UTF-8") as file:
    USER_QUERIES = [linea.strip() for linea in file]


logger = get_console_logger()

# 0 is llama3-70B

llm1 = ChatOCIGenAI(
    model_id=MODEL_LIST[0],
    service_endpoint=ENDPOINT,
    compartment_id=COMPARTMENT_OCID,
    model_kwargs={"temperature": 0, "max_tokens": 2048},
)

model_list = [
    ChatOCIGenAI(
        model_id=MODEL_LIST[0],
        service_endpoint=ENDPOINT,
        compartment_id=COMPARTMENT_OCID,
        model_kwargs={"temperature": 0, "max_tokens": 2048},
    ),
    ChatOCIGenAI(
        model_id=MODEL_LIST[1],
        service_endpoint=ENDPOINT,
        compartment_id=COMPARTMENT_OCID,
        model_kwargs={"temperature": 0, "max_tokens": 2048},
    ),
]

engine = create_db_engine()

SCHEMA = get_formatted_schema(engine, llm1)

N_QUERIES = 0
N_OK = 0

for user_query in tqdm(USER_QUERIES):
    N_QUERIES += 1

    sql_query = generate_sql_query_with_models(
        user_query, SCHEMA, engine, model_list, verbose=True
    )

    # generate with pairs check the sintax
    # if sintax is wrong return empty string
    if len(sql_query) > 0:
        N_OK += 1

print("")
print("Summary of Test results:")
print("Number of queries: ", N_QUERIES)
print("Number of test ok: ", N_OK)
